{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch 2 사이킷런으로 시작하는 머신러닝",
      "provenance": [],
      "collapsed_sections": [
        "qbgSJmU8kTU6",
        "_A1jcGYnOimH",
        "fiyMuAEhQs1u",
        "aEuj9PLiQzuV",
        "51HiYWgpatE1",
        "9eHzAHcebH1D",
        "8ChRhaqJJOWY",
        "CRSP3w0sd61C",
        "m3sy9eEYpc_x",
        "EAZ8XiEjVrMq",
        "pr8QKulhhhTt",
        "I7Uc31FMi9Je",
        "h90b8j31jwa_",
        "qoAeEsAImkDz",
        "AkLwwfyxML06",
        "sqaqGIurOMIB",
        "NiqntpjjYN_F",
        "mm7f6PlbaNkm",
        "zQYV0XXtj29l",
        "y9Rieta2lKrY",
        "sEYcVef5mR_l",
        "To0HRbc_qIrp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgs91GimDjeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbgSJmU8kTU6",
        "colab_type": "text"
      },
      "source": [
        "# 02 **첫 번째 머신러닝 만들기 - 붓꽃 품종 예측하기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhHPbtQ0BuAQ",
        "colab_type": "text"
      },
      "source": [
        "붓꽃 데이터 세트로 붓꽃의 품종을 분류하는 머신러닝 모델 만들기."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlfW4ZAXB9a_",
        "colab_type": "text"
      },
      "source": [
        "분류는 대표적인 지도학습 방법이다.\n",
        "- 지도학습은 학습을 위한 다양한 <u>피쳐</u>와 분류 결정값인 <u>레이블</u> 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측한다.\n",
        "- 즉, 명확한 정답이 주어진 데이터를 먼저 학습한 뒤, 미지의 정답을 예측하는 방식이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tIoli7OCwYl",
        "colab_type": "text"
      },
      "source": [
        "먼저 사이킷런에서 사용할 모듈을 임포트한다.\n",
        "- `sklearn.datasets`(사이킷런에서 제공하는 데이터셋), `sklearn.tree`(트리 기반 ML 알고리즘), `sklearn.model_selection`(데이터를 분리하거나 최적의 하이퍼 파라미터로 평가하기 위한 모듈).\n",
        "- `load_iris()`로 붓꽃 데이터셋을 생성하고, `DecisionTreeClassifier()`를 ML 알고리즘으로 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taeRCF-QkIbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1lB0jgdDe-V",
        "colab_type": "text"
      },
      "source": [
        "붓꽃 데이터셋을 로딩한 후, DataFrame으로 변환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCPAqfDgDVO6",
        "colab_type": "code",
        "outputId": "e55b2a7c-3477-4286-9812-03059345a724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# 붓꽃 데이터셋 로딩\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris 데이터셋에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있다.\n",
        "iris_data = iris.data\n",
        "\n",
        "# iris.target은 붓꽃 데이터셋에서 레이블 데이터를 numpy로 가지고 있다.\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터셋을 자세히 보기 위해 DataFrame으로 변환한다.\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target명: ['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  label\n",
              "0                5.1               3.5  ...               0.2      0\n",
              "1                4.9               3.0  ...               0.2      0\n",
              "2                4.7               3.2  ...               0.2      0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR40pDVUFGOy",
        "colab_type": "text"
      },
      "source": [
        "다음, 학습용 데이터와 테스트용 데이터를 분리해보자.\n",
        "- `train_test_split()`을 이용하면 데이터를 `test_size` 파라미터 입력 값의 비율로 분할한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3quZbSlExW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,\n",
        "                                                    test_size=0.2, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyubKhwJFg0l",
        "colab_type": "text"
      },
      "source": [
        "`train_test_split()`은 호출 시 무작위로 데이터를 분리하므로, `random_state`를 지정하지 않으면 수행할 때마다 다른 분류를 만든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su_hWl1RFw0I",
        "colab_type": "text"
      },
      "source": [
        "이제 이 데이터를 기반으로 의사 결정 트리를 이용해 학습과 예측을 수행해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EabiiYy2GeGH",
        "colab_type": "code",
        "outputId": "a6d25698-867b-40ff-c3b5-deb3807d7855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# DecisionTreeClassifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=11, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDUJmQGlGv2n",
        "colab_type": "text"
      },
      "source": [
        "학습된 `DecisionTreeClassifier` 객체를 이용해 예측을 수행하자.\n",
        "- 예측은 **반드시** 학습 데이터가 아닌 다른 데이터를 이용해야 한다.\n",
        "- `predict()` 메서드에 테스트 세트를 입력해 호출하면 테스트 세트에 대한 예측값을 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WKlXPkWGgvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습이 완료된 DecisionTreeClassifer 객체에서 테스트 세트로 예측 수행.\n",
        "pred = dt_clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zFF4M4kHp_T",
        "colab_type": "text"
      },
      "source": [
        "예측 결과를 기반으로 `DecisionTreeClassifier`의 예측 성능을 평가해 보자.\n",
        "- 성능 평가 방법은 여러 가지가 있는데, 여기서는 정확도를 측정한다. 정확도는 예측값이 실제값과 얼마나 일치하는지 평가하는 지표다.\n",
        "- 사이킷런은 정확도 측정을 위해 `accuracy_score()` 함수를 제공한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1tJbn4iHZtk",
        "colab_type": "code",
        "outputId": "ce36f6aa-e57b-455b-965b-14b09ba40556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jN7lA2yJgP_",
        "colab_type": "text"
      },
      "source": [
        "붓꽃 데이터셋 분류 프로세스를 정리하면 다음과 같다:\n",
        "1. **데이터셋 분리**: 데이터를 학습 데이터와 테스트 데이터로 분리한다.\n",
        "2. **모델 학습**: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킨다.\n",
        "3. **예측 수행**: 학습된 ML 모델을 이용해 테스트 데이터의 분류를 예측한다.\n",
        "4. **평가**: 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WAZAppLJ5CT",
        "colab_type": "code",
        "outputId": "464dfc5a-0725-4966-eb5e-4222340b285f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# 전체 과정\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_data = iris.data\n",
        "iris_label = iris.target\n",
        "\n",
        "iris_df = pd.DataFrame(iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,\n",
        "                                                    test_size=.2, random_state=11)\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "pred = dt_clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, pred))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A1jcGYnOimH",
        "colab_type": "text"
      },
      "source": [
        "# 03 **사이킷런의 기반 프레임워크 익히기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiyMuAEhQs1u",
        "colab_type": "text"
      },
      "source": [
        "#### **Estimator 이해 및 fit(), predict() 메서드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkUpV_OjO7X6",
        "colab_type": "text"
      },
      "source": [
        "사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 엿보이는 패키지다.\n",
        "- ML 모델 학습을 위해 `fit()`을, 모델의 예측을 위해 `predict()` 메서드를 제공한다.\n",
        "- 사이킷런은 많은 유형의 Classifier와 Regressor를 제공하는데, 둘을 합쳐 Estimator 클래스라고 부른다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjL0F_WGPZ_O",
        "colab_type": "text"
      },
      "source": [
        "evaluation 함수(`cross_val_score()`), 하이퍼 파라미터 튜닝 클래스(`GridSearchCV()`)의 경우 Estimator를 인자로 받는다. \n",
        "- `cross_val_score`나 `GridSearchCV()` 함수에 Estimator를 인자로 받고 `fit()`이나 `predict()`를 호출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ep5Ht5QTaX",
        "colab_type": "text"
      },
      "source": [
        "비지도학습인 차원 축소, 클러스터링, 피처 추출 등을 구현한 클래스는 대부분 `fit()`과 `transform()`을 적용한다.\n",
        "- 여기서 `fit()`은 학습을 의미하는 것이 아니라, 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업.\n",
        "- 사전 구조를 맞추면 실제 작업은 `transform()`으로 수행한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEuj9PLiQzuV",
        "colab_type": "text"
      },
      "source": [
        "#### **내장된 예제 데이터셋**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx0gU__SQ23N",
        "colab_type": "text"
      },
      "source": [
        "사이킷런에 내장되어 있는 데이터셋은 \n",
        "- 분류나 회귀를 연습하기 위한 예제용도의 데이터셋이나,\n",
        "- 분류나 클러스터링을 위해 표본 데이터로 생성될 수 있는 데이터셋으로 나뉜다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrQqlFo0RQkk",
        "colab_type": "text"
      },
      "source": [
        "예제 데이터:\n",
        "\n",
        "`datasets.load_boston()`: 회귀 용도. 보스턴 집 피처들과 가격에 대한 데이터셋.\n",
        "\n",
        "`datasets.load_diabetes()`: 회귀 용도. 당뇨 데이터셋.\n",
        "\n",
        "`datasets.load_digits()`: 분류 용도. 0~9까지 숫자 이미지 픽셀 데이터셋."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cVltvD2Rxow",
        "colab_type": "text"
      },
      "source": [
        "`fetch` 명령\n",
        "- `fetch` 계열의 명령은 인터넷에서 내려받아 홈 디렉터리 아래의 `scikit_learn_data`라는 서브 디렉터리에 저장 후 추후 불러들이는 데이터다.\n",
        "\n",
        "`fetch_covtype()`: 회귀 분석용 토지 조사 자료\n",
        "\n",
        "`fetch_20newsgroups()`: 뉴스 그룹 텍스트 자료\n",
        "\n",
        "`fetch_olivetti_faces()` `fetch_lfw_people()`, `fetch_lfw_pairs()`: 얼굴 이미지 자료\n",
        "\n",
        "`fetch_rcv1()`: 로이터 뉴스 말뭉치\n",
        "\n",
        "`fetch_mldata()`: ML 웹사이트에서 다운로드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95x3IlNLSn77",
        "colab_type": "text"
      },
      "source": [
        "분류와 클러스터링을 위한 표본 데이터 생성기:\n",
        "\n",
        "`datasets.make_classification()`: 분류를 위한 데이터셋을 만든다. 높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성해 준다.\n",
        "\n",
        "`datasets.make_blobs()`: 클러스터링을 위한 데이터셋을 무작위로 생성한다. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터셋을 쉽게 만들어 준다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpJq_4YvYRwq",
        "colab_type": "text"
      },
      "source": [
        "사이킷런에 내장된 분류/회귀 데이터셋은 일반적으로 딕셔너리 형태로 되어있다.\n",
        "- 키는 보통 `data`, `target`, `target_name`, `feature_names`, `DESCR`로 구성되어 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQd063yEYwdG",
        "colab_type": "text"
      },
      "source": [
        "`data`, `target`은 넘파이 배열(ndarray)타입, `target_names`, `feature_names`는 넘파이 배열 또는 리스트 타입. `DESCR`는 스트링 타입.\n",
        "- 피처의 데이터 값을 반환받기 위해선 내장 데이터셋 API를 호출한 뒤에 그 Key 값을 지정하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezXo5vXuQ1sw",
        "colab_type": "code",
        "outputId": "a1197672-a1d1-4758-9cb4-2da7cfd794f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGduis_VZXJI",
        "colab_type": "text"
      },
      "source": [
        "Bunch 클래스는 파이썬 딕셔너리 자료형과 유사하다.\n",
        "- 딕셔너리 형태이므로 `load_iris()` 데이터셋의 key 값을 확인해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUwek8P0ZKL4",
        "colab_type": "code",
        "outputId": "3554e09a-1f61-48bb-f18e-3f92d98a840a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51HiYWgpatE1",
        "colab_type": "text"
      },
      "source": [
        "# 04 **Model Selection 모듈 소개**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc4IyWNoa60i",
        "colab_type": "text"
      },
      "source": [
        "`model_selection` 모듈은 학습/테스트 데이터셋을 분리하거나 교차 검증 분할 및 평가, 그리고 Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스를 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eHzAHcebH1D",
        "colab_type": "text"
      },
      "source": [
        "#### **학습/테스트 데이터셋 분리 - train_test_split()**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2n7maqCb6dj",
        "colab_type": "text"
      },
      "source": [
        "`train_test_split()`의 반환값은 튜플 형태이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W4iUpoQcYQG",
        "colab_type": "text"
      },
      "source": [
        "붓꽃 데이터셋을 3:7 비율로 분리하고, `random_state`를 121로 변경해 데이터셋을 변화시켜 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYJZCp35ZhYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=.3, random_state=121)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEuAAv6Pcq29",
        "colab_type": "text"
      },
      "source": [
        "학습 데이터를 기반으로 `DecisionTreeClassifier`를 학습하고 모델을 이용해 예측 정확도를 측정해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qT1neXBcpSL",
        "colab_type": "code",
        "outputId": "492dcb02-fce8-4cff-eb38-0c0c8179b206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도:0.9556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChRhaqJJOWY",
        "colab_type": "text"
      },
      "source": [
        "#### **교차 검증**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNvwKcYSdO9w",
        "colab_type": "text"
      },
      "source": [
        "교차 검증을 간략히 설명하자면 본고사를 치르기 전에 모의고사를 여러 번 보는 것.\n",
        "- 본고사가 테스트 세트에 대해 평가하는 거라면, 모의고사는 교차 검증에서 많은 학습과 검증 세트에서 알고리즘 학습과 평가를 수행하는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76aFDzjuderp",
        "colab_type": "text"
      },
      "source": [
        "대부분의 ML 모델의 성능 평가는 교차 검증 기반으로 1차 평가를 한 뒤에, 최종적으로 테스트 세트에 적용해 평가하는 프로세스.\n",
        "- 학습 데이터를 다시 분할하여 학습 데이터와 학습된 모델의 성능을 일차 평가하는 검증 데이터로 나눈다.\n",
        "- 테스트 세트는 모든 학습/검증 과정이 완료된 후 최종적으로 성능을 평가하기 위한 데이터셋이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRSP3w0sd61C",
        "colab_type": "text"
      },
      "source": [
        "##### **K 폴드 교차 검증**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQEAB_1hd873",
        "colab_type": "text"
      },
      "source": [
        "K개의 데이터 폴드 세트를 만들어 K번만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법.\n",
        "- 사이킷런에서는 K 폴드 교차 검증 프로세스를 구현하기 위해 `KFold`와 `StratifiedKFold` 클래스를 제공한다.\n",
        "- 붓꽃 데이터셋에 적용해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgzwQWqZc67s",
        "colab_type": "code",
        "outputId": "c4ad8560-4a59-461d-da40-06deec229cef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터셋 크기:', features.shape[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "붓꽃 데이터셋 크기: 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxXHhjLQoryw",
        "colab_type": "text"
      },
      "source": [
        "KFold 객체를 생성했으니 교차 검증 점수를 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJzwXIQ9lSPv",
        "colab_type": "code",
        "outputId": "556ad4a9-b9de-4d87-d873-bbd11cc21d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split()을 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "  # kfold.split()으로 반환된 인덱스를 이용해 학습, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index],  features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  # 학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter += 1\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "        .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도: 1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도: 0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스: [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도: 0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스: [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도: 0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스: [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도: 0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스: [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3sy9eEYpc_x",
        "colab_type": "text"
      },
      "source": [
        "##### **Stratified K 폴드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fWUMm0VphVM",
        "colab_type": "text"
      },
      "source": [
        "`StratifiedKFold`는 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식.\n",
        "- 불균형한 분포란 특정 레이블 값이 특이하게 많거나 매우 적어 값의 분포가 한 쪽으로 치우치는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9CgvSjpvjr",
        "colab_type": "text"
      },
      "source": [
        "먼저 K 폴드가 어떤 문제를 가지고 있는지 확인하고, 이를 사이킷런의 `StratifiedKFold` 클래스를 이용해 개선해 보자.\n",
        "- 붓꽃 데이터셋을 간단하게 DataFrame으로 생성하고 레이블 값의 분포도를 확인하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwErQwuAmpAS",
        "colab_type": "code",
        "outputId": "f7d38c7e-cd95-46f3-b066-b196ea56a7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yb5c7BCqPtr",
        "colab_type": "text"
      },
      "source": [
        "모두 50개로 동일하다. 붓꽃 데이터셋 label을 KFold로 3개로 나눠보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhBPSjMqqNgK",
        "colab_type": "code",
        "outputId": "488325ab-0179-43c9-f5c9-7ee7a7f6384d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter +=1 \n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGfkt2Eysw34",
        "colab_type": "text"
      },
      "source": [
        "학습 레이블과 검증 레이블이 완전히 다른 값으로 추출되었다. 이런 유형으로 교차 검증 데이터셋을 분할하면 검증 예측 정확도는 0이 될 수밖에 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khYQvuuEs7CN",
        "colab_type": "text"
      },
      "source": [
        "이번에는 동일한 데이터 분할을 `StratifiedKFold`로 수행하고 학습/검증 레이블 데이터의 분포도를 확인해 보자.\n",
        "- KFold와 상당히 유사한데, 하나 큰 차이는 `StratifiedKFold`는 레이블 데이터 분포에 따라 데이터를 나누기 때문에, `split()` 메서드에 인자로 피처 데이터셋과 레이블 데이터셋도 반드시 필요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98fn_NfWrKKY",
        "colab_type": "code",
        "outputId": "277de02b-6ae5-4637-abbc-6e500b4784a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter += 1\n",
        "  label_train = iris_df['label'].iloc[train_index]\n",
        "  label_test = iris_df['label'].iloc[test_index]\n",
        "  print('## 교차검증: {0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## 교차검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWt-1CNNy7jA",
        "colab_type": "text"
      },
      "source": [
        "이제 `StratifiedKFold`를 이용해 붓꽃 데이터를 교차 검증해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xBTgu7WycFa",
        "colab_type": "code",
        "outputId": "f3463b3c-5d54-4d47-bac3-8c24fce02023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "# StratifiedKFold의 split() 호출 시 반드시 레이블 데이터셋도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  # split()으로 반환된 인덱스를 이용해 학습, 검증용 테스트 데이터셋 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "\n",
        "  # 학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "        .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "print('\\n##교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.round(np.mean(cv_accuracy), 4))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "#2 교차 검증 정확도: 0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "#3 교차 검증 정확도: 0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "##교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPhHaQhP9N3t",
        "colab_type": "text"
      },
      "source": [
        "##### **교차 검증을 보다 간편하게 - `cross_val_score()`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo_szvWz979S",
        "colab_type": "text"
      },
      "source": [
        "사이킷런은 교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API를 제공한다. \n",
        "- `cross_val_score()` 수행 후 반환 값은 `scoring` 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환한다.\n",
        "- `cross_val_score()`는 classifier가 입력되면 `StratifiedKFold`, regressor인 경우 계층별 교차 검증을 사용할 수 없어 `KFold` 방식으로 분할한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ1EgfeL-gb5",
        "colab_type": "text"
      },
      "source": [
        "`cross_val_score()`의 자세한 사용법을 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaOqoKuP0RSa",
        "colab_type": "code",
        "outputId": "9e484eed-d767-4ede-f1a1-06e05a92278b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores), 4))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP0-GAEQHgoA",
        "colab_type": "text"
      },
      "source": [
        "`cross_val_score()`는 `cv`로 지정된 횟수만큼 `scoring` 파라미터로 지정된 평가 지표로 평가 결괏값을 배열로 반환한다.\n",
        "- 일반적으로 배열을 평균해 평가 수치로 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4885DixTHr64",
        "colab_type": "text"
      },
      "source": [
        "`cross_val_score()`와 비슷한 API로 `cross_validate()`가 있다.\n",
        "- `cross_val_score()`는 하나의 평가 지표만 가능하지만, `cross_validate()`는 여러 개의 평가 지표를 반환할 수 있다.\n",
        "- 또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공한다. 하지만 `cross_val_score()`가 더 자주 사용된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAZ8XiEjVrMq",
        "colab_type": "text"
      },
      "source": [
        "#### **GridSearchCV() - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o61WVSOV0e7",
        "colab_type": "text"
      },
      "source": [
        "하이퍼 파라미터가 정확히 어떤 것인지 아직 설명하지 않았지만, 그래도 그것을 어떻게 튜닝하는지 아는 것이 도움이 될 수 있기에 먼저 들어간다.\n",
        "- 사이킷런은 `GridSearchCV()`를 이용해 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력해 최적의 파라미터를 도출할 수 있는 방안을 제공한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3dXnbVDXn0q",
        "colab_type": "text"
      },
      "source": [
        "붓꽃 데이터에 `GridSearchCV()`를 적용해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6FtA44VwDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, \n",
        "                                                    test_size=.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### 파라미터를 딕셔너리 형태로 결정\n",
        "parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFVSCClqY9_p",
        "colab_type": "text"
      },
      "source": [
        "`GridSearchCV()` 객체에 `fit()` 메서드를 수행하면 `param_grid`에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고, 그 결과를 `cv_result_` 속성에 기록한다.\n",
        "- `cv_results_`를 Pandas의 DataFrame으로 변환하면 내용을 좀 더 쉽게 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxnJkJhjYRWN",
        "colab_type": "code",
        "outputId": "25cdfbfd-375c-4127-f1c8-9d2d50675213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 결정.\n",
        "### refit=True 가 default. True면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가.\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  ...  split2_test_score\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}  ...               0.70\n",
              "1  {'max_depth': 1, 'min_samples_split': 3}  ...               0.70\n",
              "2  {'max_depth': 2, 'min_samples_split': 2}  ...               0.95\n",
              "3  {'max_depth': 2, 'min_samples_split': 3}  ...               0.95\n",
              "4  {'max_depth': 3, 'min_samples_split': 2}  ...               0.95\n",
              "5  {'max_depth': 3, 'min_samples_split': 3}  ...               0.95\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgvtzViadOJ",
        "colab_type": "text"
      },
      "source": [
        "- `rank_test_score`이 높을수록 예측 성능이 높다는 것.\n",
        "- `mean_test_score`는 세 개의 성능 수치를 평균한 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3H7SBN8a9jM",
        "colab_type": "text"
      },
      "source": [
        "`GridSearchCV()` 객체의 `fit()`을 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그때의 평가 결과 값이 각각 `best_params_`, `best_score_` 속성에 기록된다.\n",
        "- `cv_results_`의 `rank_test_score`가 1일 때의 값."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-ZKltUaEQi",
        "colab_type": "code",
        "outputId": "6d29dd2f-0b7e-49ab-9d4a-160ceda75629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
        "print('GridSearchCV 최고 정확도:{:0.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도:0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C__UKtTOcdRh",
        "colab_type": "text"
      },
      "source": [
        "이미 학습된 `best_estimator_`를 이용해 앞에서 `train_test_split()`으로 분리한 테스트 데이터셋에 대해 예측하고 성능을 평가해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKtOZTiRbbYb",
        "colab_type": "code",
        "outputId": "6ead56e7-c094-408c-cf1e-5b48c8c23e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없다.\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터셋 정확도:{:0.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터셋 정확도:0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jPXfvGkdAZ0",
        "colab_type": "text"
      },
      "source": [
        "일반적으로 학습 데이터를 `GridSearchCV`를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 평가하는 것이 일반적인 적용 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_QrKy91dKyV",
        "colab_type": "text"
      },
      "source": [
        "**정리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4UjOK-sc6uV",
        "colab_type": "code",
        "outputId": "0e02d56b-915b-4ab1-87de-b06d9a95290a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
        "                                                    test_size=.2, random_state=121)\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "parameters = {'max_depth': [1, 2, 3],\n",
        "              'min_samples_split': [2, 3]\n",
        "              }\n",
        "\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3)\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "cv_results = pd.DataFrame(grid_dtree.cv_results_)\n",
        "cv_results[['split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'rank_test_score']]\n",
        "\n",
        "print('최적의 파라미터: ', grid_dtree.best_params_)\n",
        "print('최적의 스코어:{:0.4f}'.format(grid_dtree.best_score_))\n",
        "\n",
        "estimator = grid_dtree.best_estimator_\n",
        "\n",
        "pred = estimator.predict(X_test)\n",
        "\n",
        "print('테스트 데이터셋에 대한 최고 성능:{:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최적의 파라미터:  {'max_depth': 3, 'min_samples_split': 2}\n",
            "최적의 스코어:0.9750\n",
            "테스트 데이터셋에 대한 최고 성능:0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GwUbu3Gd5VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr8QKulhhhTt",
        "colab_type": "text"
      },
      "source": [
        "# 05 **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4mqG2V9h0BT",
        "colab_type": "text"
      },
      "source": [
        "ML 알고리즘은 데이터에 기반하고 있기 때문에 어떤 데이터를 입력으로 가지느냐에 따라 결과도 크게 달라질 수 있다.\n",
        "- 사이킷런의 ML 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 할 사항이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsotHZ7viRQM",
        "colab_type": "text"
      },
      "source": [
        "1. 결손값은 허용되지 않는다.\n",
        "  - `Null` 값이 얼마 되지 않으면 평균값 등으로 간단히 대체할 수 있다. `Null` 값이 대부분이라면 해당 피처는 드롭하는게 좋다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pnz83V03ish2",
        "colab_type": "text"
      },
      "source": [
        "2. ML 알고리즘은 문자열 값을 입력 값으로 허용하지 않는다.\n",
        "  - 텍스트형 피처는 피처 벡터화 등의 기법으로 인코딩하거나 불필요하다면 드롭한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Uc31FMi9Je",
        "colab_type": "text"
      },
      "source": [
        "### **데이터 인코딩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6peyWuhjGNv",
        "colab_type": "text"
      },
      "source": [
        "대표적인 인코딩 방식은 **레이블 인코딩**(Label encoding)과 **원-핫 인코딩**(One-Hot encoding)이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h90b8j31jwa_",
        "colab_type": "text"
      },
      "source": [
        "##### **레이블 인코딩**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv0ZkX-aj238",
        "colab_type": "text"
      },
      "source": [
        "레이블 인코딩은 `LabelEncoder` 클래스로 구현된다. 객체를 생성한 후 `fit()`, `transform()`을 호출해 인코딩을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ktoMLwAhk_B",
        "colab_type": "code",
        "outputId": "9dee4e32-67e1-477f-e0b9-a5ed7169a820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성 후 fit(), transform()으로 레이블 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:', labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n52pMir2kj-g",
        "colab_type": "text"
      },
      "source": [
        "위 예제는 데이터가 작아서 문자열 값이 어떤 숫자 값으로 인코딩됐는지 알 수 있지만, 많은 경우 알지 힘들다.\n",
        "- 이 경우 LabelEncoder 객체의 `classes_` 속성값으로 확인하면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCSuHVXckfmy",
        "colab_type": "code",
        "outputId": "b9229b99-c413-4c79-95f1-29defad3b501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoder.classes_"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['TV', '냉장고', '믹서', '선풍기', '전자레인지', '컴퓨터'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8hmlcK4k8Ge",
        "colab_type": "text"
      },
      "source": [
        "`classes_` 속성은 0번부터 순서대로 변환된 인코딩 값에 대한 원본값을 가지고 있다.\n",
        "- `inverse_transform()`을 통해 인코딩된 값을 다시 디코딩할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enps6qoNkxK5",
        "colab_type": "code",
        "outputId": "45db5c74-8832-46ea-8d1f-3aadb603cb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['전자레인지', '컴퓨터', '믹서', 'TV', '냉장고', '냉장고', '선풍기', '선풍기'],\n",
              "      dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkjiyhmnl_Rv",
        "colab_type": "text"
      },
      "source": [
        "**정리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwhHSkGQlFvQ",
        "colab_type": "code",
        "outputId": "36179709-cb6a-4547-8b37-c79eaa110d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "\n",
        "print('인코딩 클래스:', encoder.classes_)\n",
        "print('디코딩 클래스:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
            "디코딩 클래스: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diJccr80mAjQ",
        "colab_type": "text"
      },
      "source": [
        "레이블 인코딩은 간단하게 문자열 값을 숫자형 카테고리 값으로 변환한다. 하지만 예측 성능이 떨어지는 경우가 발생할 수 있다.\n",
        "- 냉장고가 1, 믹서가 2로 변환되면, 1보다 2가 더 큰 값이므로 특정 ML 알고리즘에서 가중치가 부여될 수 있기 때문에."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im40T6aNmjb4",
        "colab_type": "text"
      },
      "source": [
        "이러한 특성 때문에 `LabelEncoder`는 선형 회귀같은 알고리즘에는 적용하지 않아야 한다.\n",
        "- 트리 계열의 ML 알고리즘은 숫자의 특성을 반영하지 않으므로 레이블 인코딩도 별 문제가 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoAeEsAImkDz",
        "colab_type": "text"
      },
      "source": [
        "##### **원-핫 인코딩**(One-Hot Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEAuUhKKJ8lZ",
        "colab_type": "text"
      },
      "source": [
        "원-핫 인코딩은 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1, 나머지 칼럼에는 0을 표시한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDioVvagKSV4",
        "colab_type": "text"
      },
      "source": [
        "원-핫 인코딩은 사이킷런에서 `OneHotEncoder` 클래스로 변환이 가능하다. 하지만 주의할 점이 있다.\n",
        "- 첫 번째는 모든 문자열 값이 숫자형 값으로 변환되야 한다는 것.\n",
        "- 두 번째는 입력 값으로 2차원 데이터가 필요하다는 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z9AvNDtlXc0",
        "colab_type": "code",
        "outputId": "0dee5e66-997a-46f0-c4d2-8521a3576807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환한다.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "\n",
        "# 2차원 데이터로 변환한다.\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩을 적용한다.\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mjzatlr1LLcF",
        "colab_type": "text"
      },
      "source": [
        "판다스엔 원-핫 인코딩을 쉽게 지원하는 API가 있다. `get_dummies()`를 이용하면 된다.\n",
        "- 문자열 카테고리 값을 숫자 형으로 변환할 필요 없이 바로 변환할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPUBMF6QLI1q",
        "colab_type": "code",
        "outputId": "7ec2914f-c73d-49bd-b4b8-e678e71e6d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "df = pd.DataFrame({'item': ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_전자레인지</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
              "0        1         0        0         0           0         0\n",
              "1        0         1        0         0           0         0\n",
              "2        0         0        0         0           1         0\n",
              "3        0         0        0         0           0         1\n",
              "4        0         0        0         1           0         0\n",
              "5        0         0        0         1           0         0\n",
              "6        0         0        1         0           0         0\n",
              "7        0         0        1         0           0         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkLwwfyxML06",
        "colab_type": "text"
      },
      "source": [
        "### **피처 스케일링과 정규화**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJI-WP-HMb05",
        "colab_type": "text"
      },
      "source": [
        "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 피처 스케일링이라고 한다. 대표적인 방법에는 **표준화**와 **정규화**가 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU1KYO_9MmwH",
        "colab_type": "text"
      },
      "source": [
        "표준화(Standardization)은 데이터의 평균이 0이고, 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것을 의미한다.\n",
        "- 표준화를 통해 변환될 피처 $x$의 새 데이터를 $x$라 할 때, \n",
        "  $$x=\\frac{x_i-\\bar{x}}{std(x)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcOo8iTYNWCy",
        "colab_type": "text"
      },
      "source": [
        "정규화(Normalization)는 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 것. 개별 데이터의 크기를 같은 단위로 변경하는 것.\n",
        "- 정규화된 새로운 데이터 $x$는\n",
        "  $$x=\\frac{x_i-min(x)}{max(x)-min(x)}$$\n",
        "- 사이킷런의 정규화는 선형대수의 정규화 개념이 적용되었다. 개별 벡터의 크기를 맞추기 위해 변환하는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwySA214OC6y",
        "colab_type": "text"
      },
      "source": [
        "**정리**\n",
        "- 표준화는 데이터를 가우시안 정규 분포에 맞게 변환시키는 것.\n",
        "- 정규화는 데이터를 같은 단위로 변경하는 것."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqaqGIurOMIB",
        "colab_type": "text"
      },
      "source": [
        "### **StandardScaler**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0lZVALLOP4b",
        "colab_type": "text"
      },
      "source": [
        "가우시안 정규 분포를 가질 수 있도록 데이터를 변환하는 것은 몇몇 알고리즘에 중요하게 작용한다.\n",
        "- SVM, 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다 가정하고 구현됐기 때문에 사전에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 될 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFTbTzL2P3P_",
        "colab_type": "text"
      },
      "source": [
        "StandardScaler가 어떻게 데이터 값을 변환하는지 데이터셋으로 확인해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvN04oi0Lo91",
        "colab_type": "code",
        "outputId": "ebf6ce97-1c4f-4ff8-df54-c19cf92ad994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터셋을 로딩하고 DataFrame으로 변환한다.\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNW7SGQ3VI3V",
        "colab_type": "text"
      },
      "source": [
        "이제 StandardScaler를 이용해 각 피처를 한 번에 표준화해 변환해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AFI4kxcVBm3",
        "colab_type": "code",
        "outputId": "45f9acf1-7529-414a-e242-cd007261e6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler 객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler로 데이터셋 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터셋이 NumPy ndarray로 반환돼 이를 DataFrame으로 변환.\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiqntpjjYN_F",
        "colab_type": "text"
      },
      "source": [
        "### **MinMaxScaler**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFTLgBDeYilL",
        "colab_type": "text"
      },
      "source": [
        "`MinMaxScaler`는 데이터값을 0과 1 사이 범위 값으로 변환한다.\n",
        "- 음수 값이 있다면 -1에서 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW6nkxctV4ke",
        "colab_type": "code",
        "outputId": "83299be5-7d00-4d86-a0fb-5683e1a3f845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler로 데이터셋 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform()시 스케일 변환된 데이터셋이 NumPy ndarray로 반환되 이름 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm7f6PlbaNkm",
        "colab_type": "text"
      },
      "source": [
        "### **학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ge1GzygLQ_",
        "colab_type": "text"
      },
      "source": [
        "Scaler 객체를 이용해 데이터의 스케일링 변환 시 `fit()`, `transform()`, `fit_transform()` 를 사용한다. 하지만 `fit_transform()`은 주의해야 한다. \n",
        "- Scaler 객체를 이용해 학습 데이터셋으로 `fit()`, `transform()`을 적용하면 테스트셋에는 `fit()`을 수행하지 않고 학습 데이터셋에 `fit()`을 수행한 결과를 이용해 `transform()` 변환을 적용해야 한다는 것."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5qHdeWSaMNj",
        "colab_type": "code",
        "outputId": "6ced7ca1-8082-4fdc-d50e-f3f52680f587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 6).reshape(-1, 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 한다.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRNyAXnehy2N",
        "colab_type": "text"
      },
      "source": [
        "`fit_transform()`은 `fit()`과 `transform()`을 순차적으로 수행하는 메소드라 학습 데이터에서는 상관없지만, 테스트 데이터에서는 절대 사용해선 안된다.\n",
        "- 이런 상황이 발생하므로 학습/테스트셋으로 분리하기 전에 되도록 전체 데이터셋에 스케일링을 적용한 뒤 분리하는게 낫다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reWQEdNDiF4F",
        "colab_type": "text"
      },
      "source": [
        "**정리**\n",
        "1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습/테스트 데이터로 분리.\n",
        "2. 1번이 안된다면 테스트 데이터 변환 시 `fit()`이나 `fit_transform()`을 적용하지 않고 학습 데이터로 이미 `fit()`된 Scaler 객체를 이용해 `transform()`으로 변환."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQYV0XXtj29l",
        "colab_type": "text"
      },
      "source": [
        "# 06 **사이킷런으로 수행하는 타이타닉 생존자 예측**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9Rieta2lKrY",
        "colab_type": "text"
      },
      "source": [
        "### **캐글 셋업**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH-irizuhnv4",
        "colab_type": "code",
        "outputId": "048fe88f-377b-4f74-b417-bdc8c1118220",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.4.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e634486-acff-4874-8ece-2c1e2ad9b595\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1e634486-acff-4874-8ece-2c1e2ad9b595\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"tjdrms2023\",\"key\":\"420f91d78b4ea1dbbe26e3078903b138\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxmIRJN4lTMQ",
        "colab_type": "code",
        "outputId": "f9790ac0-f1d7-4315-85de-dcce7618243d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 파일 제대로 업로드됐는지 확인하기.\n",
        "ls -1ha kaggle.json"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t5DjNpUlWbh",
        "colab_type": "code",
        "outputId": "7d2527aa-f828-456d-8f23-150253fd5db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Permission Warning 이 일어나지 않도록 \n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# 본인이 참가한 모든 대회 보기 \n",
        "!kaggle competitions list"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                               deadline             category            reward  teamCount  userHasEntered  \n",
            "------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                                  2030-01-01 00:00:00  Getting Started  Knowledge       2390           False  \n",
            "titanic                                           2030-01-01 00:00:00  Getting Started  Knowledge      18492            True  \n",
            "house-prices-advanced-regression-techniques       2030-01-01 00:00:00  Getting Started  Knowledge       4561            True  \n",
            "connectx                                          2030-01-01 00:00:00  Getting Started  Knowledge        321           False  \n",
            "nlp-getting-started                               2030-01-01 00:00:00  Getting Started      Kudos       2690           False  \n",
            "competitive-data-science-predict-future-sales     2020-12-31 23:59:00  Playground           Kudos       6352           False  \n",
            "prostate-cancer-grade-assessment                  2020-07-22 23:59:00  Featured           $25,000          9           False  \n",
            "halite                                            2020-06-30 23:59:00  Featured             Kudos          0           False  \n",
            "m5-forecasting-accuracy                           2020-06-30 23:59:00  Featured           $50,000       2670           False  \n",
            "m5-forecasting-uncertainty                        2020-06-30 23:59:00  Featured           $50,000        266           False  \n",
            "jigsaw-multilingual-toxic-comment-classification  2020-06-22 23:59:00  Featured           $50,000        618           False  \n",
            "tweet-sentiment-extraction                        2020-06-16 23:59:00  Featured           $15,000        579            True  \n",
            "imet-2020-fgvc7                                   2020-05-28 23:59:00  Research         Knowledge         32           False  \n",
            "abstraction-and-reasoning-challenge               2020-05-27 23:59:00  Research           $20,000        659           False  \n",
            "imaterialist-fashion-2020-fgvc7                   2020-05-26 23:59:00  Research         Knowledge         18           False  \n",
            "iwildcam-2020-fgvc7                               2020-05-26 23:59:00  Research         Knowledge         74           False  \n",
            "herbarium-2020-fgvc7                              2020-05-26 23:59:00  Research         Knowledge         59           False  \n",
            "liverpool-ion-switching                           2020-05-25 23:59:00  Research           $25,000       1907           False  \n",
            "flower-classification-with-tpus                   2020-05-11 23:59:00  Playground          Prizes        652           False  \n",
            "plant-pathology-2020-fgvc7                        2020-05-11 23:59:00  Research         Knowledge        764           False  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp2G_ul7lZab",
        "colab_type": "code",
        "outputId": "3e04a5a4-6876-429b-a995-1a0e6c4c123b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# 타이타닉 데이터 불러오기\n",
        "! kaggle competitions download -c titanic"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading gender_submission.csv to /content\n",
            "  0% 0.00/3.18k [00:00<?, ?B/s]\n",
            "100% 3.18k/3.18k [00:00<00:00, 5.61MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/59.8k [00:00<?, ?B/s]\n",
            "100% 59.8k/59.8k [00:00<00:00, 61.8MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/28.0k [00:00<?, ?B/s]\n",
            "100% 28.0k/28.0k [00:00<00:00, 24.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_t7jQgyla6f",
        "colab_type": "code",
        "outputId": "377cb8c0-753e-464b-ba76-4a2dbdcae898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 불러온 데이터 확인하기\n",
        "!ls"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender_submission.csv  kaggle.json  sample_data  test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEYcVef5mR_l",
        "colab_type": "text"
      },
      "source": [
        "### **타이타닉**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liBDuikClkjF",
        "colab_type": "code",
        "outputId": "28f22e08-f6f0-4750-b554-7fd9e9d99b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA3iD1yumHt9",
        "colab_type": "code",
        "outputId": "e50fc478-216f-4adc-c668-518e8fdf2f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "titanic_df = pd.read_csv('train.csv')\n",
        "titanic_df.head(3)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYMDbIDdmj7Q",
        "colab_type": "text"
      },
      "source": [
        "로딩된 데이터 칼럼 타입을 확인해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d_BnTPcmMtt",
        "colab_type": "code",
        "outputId": "36944602-9dcf-480b-84b4-b499a62d9249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print('\\n ### 학습 데이터 정보 ### \\n')\n",
        "print(titanic_df.info())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ### 학습 데이터 정보 ### \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1ir-qm1m8Rg",
        "colab_type": "text"
      },
      "source": [
        "ML 알고리즘은 null 값을 허용하지 않으므로 어떻게 처리할지 결정해야 한다. `fillna()` 함수를 사용한다.\n",
        "- Age의 경우는 평균 나이, 나머지 칼럼은 'N'값으로 변경한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hbtmlVXmsZk",
        "colab_type": "code",
        "outputId": "0a16a17b-b33a-4b8e-9600-fde3c3201f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
        "titanic_df['Cabin'].fillna('N', inplace=True)\n",
        "titanic_df['Embarked'].fillna('N', inplace=True)\n",
        "print('데이터 세트 Null값 개수', titanic_df.isnull().sum().sum())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 세트 Null값 개수 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzg3m7rKodp-",
        "colab_type": "text"
      },
      "source": [
        "주요한 피처 중 문자열 피처는 `Sex`, `Cabin`, `Embarked`. 이 피처들의 값 분류를 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGOAPntoNYW",
        "colab_type": "code",
        "outputId": "33cda641-6444-4f5a-c233-9a9bbf8c4e27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "print(' Sex 값 분포 :\\n', titanic_df['Sex'].value_counts())\n",
        "print('\\nCabin 값 분포:\\n', titanic_df['Cabin'].value_counts())\n",
        "print('\\nEmbarked 값 분포:\\n', titanic_df['Embarked'].value_counts())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sex 값 분포 :\n",
            " male      577\n",
            "female    314\n",
            "Name: Sex, dtype: int64\n",
            "\n",
            "Cabin 값 분포:\n",
            " N              687\n",
            "B96 B98          4\n",
            "G6               4\n",
            "C23 C25 C27      4\n",
            "D                3\n",
            "              ... \n",
            "C103             1\n",
            "C118             1\n",
            "C70              1\n",
            "E40              1\n",
            "A26              1\n",
            "Name: Cabin, Length: 148, dtype: int64\n",
            "\n",
            "Embarked 값 분포:\n",
            " S    644\n",
            "C    168\n",
            "Q     77\n",
            "N      2\n",
            "Name: Embarked, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP40vc53rrgp",
        "colab_type": "text"
      },
      "source": [
        "Cabin 속성의 경우 앞 문자만 추출하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqKOqQzTqLQx",
        "colab_type": "code",
        "outputId": "e7bf225a-5139-4999-d158-2c34c5a82d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
        "print(titanic_df['Cabin'].head(3))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    N\n",
            "1    C\n",
            "2    N\n",
            "Name: Cabin, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so0TFQo_sAJN",
        "colab_type": "text"
      },
      "source": [
        "***EDA는 생략한다***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qg9Lma8sD1-",
        "colab_type": "text"
      },
      "source": [
        "남아있는 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환하자. `LabelEncoder`를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94iPeIOFr2xd",
        "colab_type": "code",
        "outputId": "f1be8978-3f57-441a-8226-c24996440eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "from sklearn import preprocessing \n",
        "\n",
        "def encode_features(dataDF):\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le = le.fit(dataDF[feature])\n",
        "    dataDF[feature] = le.transform(dataDF[feature])\n",
        "\n",
        "  return dataDF\n",
        "\n",
        "titanic_df = encode_features(titanic_df)\n",
        "titanic_df.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500      7         3\n",
              "1            2         1       1  ...  71.2833      2         0\n",
              "2            3         1       3  ...   7.9250      7         3\n",
              "3            4         1       1  ...  53.1000      2         3\n",
              "4            5         0       3  ...   8.0500      7         3\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBPXRVTA0gfW",
        "colab_type": "text"
      },
      "source": [
        "`Sex`, `Cabin`, `Embarked` 속성이 숫자형으로 바뀌었다. 지금까지 피처를 가공한 내역을 정리하고 함수로 만들어 재사용할 수 있도록 만들자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4BJfd440TBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Null 처리 함수\n",
        "def fillna(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  return df\n",
        "\n",
        "# ML 알고리즘에 불필요한 속성 제거\n",
        "def drop_features(df):\n",
        "  df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 레이블 인코딩 수행\n",
        "def format_features(df):\n",
        "  df['Cabin'] = df['Cabin'].str[:1]\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(df[feature])\n",
        "    df[feature] = le.transform(df[feature])\n",
        "  return df\n",
        "\n",
        "# 앞에서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "  df = fillna(df)\n",
        "  df = drop_features(df)\n",
        "  df = format_features(df)\n",
        "  return df "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YPTpbxY2A6b",
        "colab_type": "text"
      },
      "source": [
        "전처리를 수행하는 함수를 만들었으니 이 함수를 이용해 원본 데이터를 가공해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgzBSqBJ2AKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원본 데이터를 재로딩하고, 피처 데이터셋과 레이블 데이터셋 추출.\n",
        "titanic_df = pd.read_csv('train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "X_titanic_df = transform_features(X_titanic_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U3PGezm2gBS",
        "colab_type": "text"
      },
      "source": [
        "`train_test_split()`를 이용해 별도의 테스트 데이터셋을 추출한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3G5jQAn2bLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
        "                                                    test_size=.2, random_state=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyC1eirZtWKn",
        "colab_type": "text"
      },
      "source": [
        "ML 알고리즘인 결정 트리, 랜덤 포레스트, 로지스틱 회귀를 사용해 타이타닉 생존자를 예측해 보자.\n",
        "- 위 알고리즘들을 사용해 학습/테스트 데이터를 기반으로 ML 모델을 학습하고(`fit()`), 예측한다(`predict()`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fjZXj-t2vRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "6685a994-de10-4c26-827b-874ab89b3180"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# DTC, RF, LR을 위한 클래스 생성\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "rf_clf = RandomForestClassifier()\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "# DTC 학습/예측/평가\n",
        "dt_clf.fit(X_train, y_train)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "print('DecisionTreeClassifier 정확도: {:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "\n",
        "# RF 학습/예측/평가\n",
        "rf_clf.fit(X_train, y_train)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "print('RandomForestClassifier 정확도: {:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "\n",
        "# LR 학습/예측/평가\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "print('LogisticRegression 정확도: {:.4f}'.format(accuracy_score(y_test, lr_pred)))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier 정확도: 0.7821\n",
            "RandomForestClassifier 정확도: 0.8492\n",
            "LogisticRegression 정확도: 0.8492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ0eIX6TlzIl",
        "colab_type": "text"
      },
      "source": [
        "다음은 교차 검증으로 결정 트리 모델을 평가해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8JtvNlxlwbu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "06c2fc9a-7abc-44bf-db5d-cb372642f858"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def exec_kfold(clf, folds=5):\n",
        "  # 폴드 세트가 5개인 KFold 객체를 생성. 폴드 수만큼 예측결과 저장을 위한 리스트 객체 생성.\n",
        "  kfold = KFold(n_splits=folds)\n",
        "  scores = []\n",
        "\n",
        "  # KFold 교차 검증 수행.\n",
        "  for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
        "    # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성.\n",
        "    X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
        "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
        "    # Classifier 학습, 예측, 정확도 계산\n",
        "    clf.fit(X_train, y_train)\n",
        "    predictions = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    scores.append(accuracy)\n",
        "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
        "\n",
        "  # 5개 fold에서의 평균 정확도 계산.\n",
        "  mean_score = np.mean(scores)\n",
        "  print('평균 정확도: {0:.4f}'.format(mean_score))\n",
        "  \n",
        "# exec_kfold 호출\n",
        "exec_kfold(dt_clf, folds=5)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증 0 정확도: 0.7542\n",
            "교차 검증 1 정확도: 0.7640\n",
            "교차 검증 2 정확도: 0.7865\n",
            "교차 검증 3 정확도: 0.7584\n",
            "교차 검증 4 정확도: 0.8258\n",
            "평균 정확도: 0.7778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFXSvNLboAv0",
        "colab_type": "text"
      },
      "source": [
        "평균 정확도는 약 77.78%. 이번에는 `cross_val_score()`를 사용해 교차 검증을 수행하자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wOyhZW6nuDe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5ea052ea-da70-48ab-e8ab-3ae45446a75d"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
        "for iter_count, accuracy in enumerate(scores):\n",
        "  print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
        "\n",
        "print(\"평균 정확도: {:.4f}\".format(np.mean(scores)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "교차 검증 0 정확도: 0.7430\n",
            "교차 검증 1 정확도: 0.7865\n",
            "교차 검증 2 정확도: 0.8202\n",
            "교차 검증 3 정확도: 0.7865\n",
            "교차 검증 4 정확도: 0.8315\n",
            "평균 정확도: 0.7935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdNntAccogFC",
        "colab_type": "text"
      },
      "source": [
        "정확도가 약간 다른 이유는 `cross_val_score()`에선 `KFold`가 아닌 `StratifiedKFold`를 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fH2TgTuopVc",
        "colab_type": "text"
      },
      "source": [
        "마지막으로 `GridSearchCV`를 사용해 최적의 하이퍼 파라미터를 찾고 예측 성능을 측정해 보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM5nyCszodOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "31022d13-e27b-4dc7-efe4-536df578fb9d"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'max_depth': [2, 3, 5, 10],\n",
        "              'min_samples_split': [2, 3, 5],\n",
        "              'min_samples_leaf': [1, 5, 8]}\n",
        "\n",
        "grid_dclf = GridSearchCV(dt_clf, parameters, scoring='accuracy', cv=5)\n",
        "grid_dclf.fit(X_train, y_train)\n",
        "\n",
        "print('GridSearchCV 최적 하이퍼 파라미터: ', grid_dclf.best_params_)\n",
        "print('GridSearchCV 최고 정확도: {:.4f}'.format(grid_dclf.best_score_))\n",
        "best_dclf = grid_dclf.best_estimator_\n",
        "\n",
        "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행.\n",
        "dpredictions = best_dclf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, dpredictions)\n",
        "print('테스트 세트에서의 DecisionTreeClassifier 정확도: {:.4f}'.format(accuracy))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 하이퍼 파라미터:  {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도: 0.7992\n",
            "테스트 세트에서의 DecisionTreeClassifier 정확도: 0.8715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU12v2nZqFCM",
        "colab_type": "text"
      },
      "source": [
        "예측 정확도가 87.15%로 향상되었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To0HRbc_qIrp",
        "colab_type": "text"
      },
      "source": [
        "# 07 **정리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HLYBueqJ9Y",
        "colab_type": "text"
      },
      "source": [
        "ML 어플리케이션은:\n",
        "1. 데이터의 가공 및 변환 과정의 전처리 작업\n",
        "2. 데이터를 학습/테스트 데이터로 분리하는 데이터셋 분리 작업\n",
        "3. 학습된 모델을 기반으로 테스트 데이터에 대한 예측\n",
        "4. 예측값과 실제값과 비교해 ML 모델에 대한 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr5WNZWp4uJL",
        "colab_type": "text"
      },
      "source": [
        "데이터의 전처리 작업은:\n",
        "- 오류 데이터의 보정이나 결손값 처리같은 데이터 클렌징 작업,\n",
        "- 레이블 인코딩이나 원-핫 인코딩같은 인코딩 작업,\n",
        "- 데이터 스케일링과 정규화 작업 등으로 이루어져 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKeYIoXx5Aql",
        "colab_type": "text"
      },
      "source": [
        "ML 모델은 학습 데이터셋으로 학습한 뒤 반드시 별도의 테스트 데이터셋으로 평가되어야 한다.\n",
        "- 이를 해결하기 위해 학습/검증 데이터로 구성된 여러 개의 폴드 세트로 분리해 교차 검증을 수행할 수 있다."
      ]
    }
  ]
}