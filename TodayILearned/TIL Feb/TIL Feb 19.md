# Machine Learning

**SVM 이해하기**

- SVM 훈련 과정에서 각 훈련 포인트들이 결정 경계를 형성하는데 얼마나 중요한지 확인.
  - 보통 결정 경계 근처 포인트들만 중요함. 이런 애들을 **Support vector**라고 부름.
- 새로운 포인트에 대한 예측은 서포트 벡터들과의 거리로 예측. 서포트 벡터들의 중요도는 `dual_coef_`에 저장됨.

<br>

**SVM 매개변수**

- gamma는 gaussian kernel 폭의 역수. 
  - Kernel에서 훈련 포인트가 영향을 미치는 범위를 조절. gamma가 작을수록 범위가 크다.
- C는 선형 모델의 규제와 비슷. C가 작을수록 규제가 커지고, 중요도가 작아진다 (과소적합됨).

<br>

**SVM 데이터 전처리**

- SVM은 좋은 모델이지만 데이터 스케일과 매개변수에 민감.
  - 특성 값의 범위가 비슷해지도록 조정해야.

<Br>

**SVM 장단점과 매개변수**

- 저차원, 작은 샘플 데이터셋에 효과적. 고차원에서도 ok. 하지만 샘플이 많으면 잘 작동 안함.
- 매개변수와 스케일에 너무 민감함. 그래서 대부분 RF나 GB사용. 비전문가에게 설명하기도 힘듬.
- 중요한 매개변수: C, kernel, kernel에 대한 매개변수.
  - rbf외에도 kernel 다수 존재. 
  - C와 gamma 모두 복잡도 조절하는 매개변수이므로 서로 같이 조절해가며 성능 향상시켜야.

<br>

**신경망(딥러닝)**

- 요즘 한창 유행중. 데이터가 많이 필요함. 가장 기본인 다층 퍼셉트론만.
- 단층 퍼셉트론: <**입력**> --(계수, 가중치)--> <**출력**>

- 다층 퍼셉트론: <**입력**> --(계수, 가중치)--> <**은닉층**> --(계수, 가중치)--> <**출력**>
  - 은닉층에서 활성화함수가 개입.
- 여기서 소개된 활성화함수는 RELU, tanh.
  - RELU 범위: 0~
  - tanh 범위: -1 ~ +1