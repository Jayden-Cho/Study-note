# Machine Learning

**특성 자동 선택**

- 특성을 추가할 수 있는 방법이 많아 원본 특성보다 늘어나기 쉬움. 특성이 많으면 모델이 복잡해지고 과대적합될 수 있음.
- <u>모두 지도학습. 타깃값이 필요함.</u>
- <u>정보 누설을 막기 위해 훈련 데이터만 사용.</u>
- 종류에는 일변량 특성 선택, 모델 기반 특성 선택, 반복적 특성 선택이 있음.

<br>

**일변량 특성**

- 분산분석이라고도 함.
- <u>모든 특성이 독립적으로 고려됨.</u>
- 각 특성과 타깃값의 통계적 관계를 파악해 기준에 따라 특성을 선택한다.
  - 특성과 타깃을 비교해 p-value을 얻고, 높은 p값부터 기준에 따라 제거한다.
- 기준은 두 가지가 있는데,
  - `SelectKBest`: 가장 중요한 특성 k개 선택.
  - `SelectPercentile`: 비율을 기준으로  선택해 추출.
- <u>빠르고, 모델링할 필요가 없고, 어느 모델에도 사용 가능하다.</u>
- 특성 선택으로 추출된 특성들은 `get_support()` 메서드로 파악 가능.
- 일변량 특성은
  - 특성이 너무 많아 모델링이 어려울 때,
  - 불필요한 특성이 있는거 같아 제거해야 할 때 사용.

<br>

**모델 기반 특성 선택**

- 지도학습 ML 모델을 사용해 중요도를 평가해 특성 선택.
  - 특성 선택에 사용된 모델과 모델링에 사용할 모델이 같을 필요는 없음.
- <u>트리기반 모델은 `feature_importance_` 로, 선형 모델은 계수의 절댓값으로 특성 선택.</u>
- <u>한 번에 모든 특성을 고려하므로 상호작용 부분을 반영할 수 있음.</u>
- 매우 복잡한 모델이고 일변량 분석보단 훨씬 강력한 방법.

<br>

**반복적 특성 선택**

- 특정 조건을 만족할 때까지 모델을 계속 생성해 특성 선택.
- 방법은 두 가지:
  - 특성 0개로 시작해 조건을 만족할 때 까지 특성 추가.
  - 모든 특성으로 시작해 조건을 만족할 때 까지 특성 제거.
- 자주 사용되는것은 재귀적 특성 제거(RFE).
  - <u>특성 중요도가 가장 낮은 특성 제거 후 새로운 모델 생성.</u>
  - <u>정의된 특성 개수가 남을 때까지 반복.</u>
- 모델을 여러 개 만드므로 시간이 꽤 오래걸림.

<br>

**종합**

- 어떤 특성을 선택할지 모르겠다면 특성 자동 선택 사용.
- <u>특성 선택만 제대로 되면 선형 모델도 RF와 성능 비슷하다.</u>
- 성능 향상에 딱히 도움되지 않지만, 여전히 중요한 방법.