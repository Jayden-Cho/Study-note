# Machine Learning

**전문가의 도움 구하기**

- <u>특성 공학은 전문가의 지식을 사용할 수 있는 중요한 영역.</u>
  - 전문가의 도움을 받지 않기 위해 ML을 사용하는 것은 맞다. 초기 데이터에서 유용한 특성을 선택할 수 있도록 도와준다.
- <u>특성을 추가한다고 반드시 ML 모델이 그 특성을 사용하는 것은 아니다.</u> 정보가 추가된다해도 문제되지 않는다.

<br>

**예제: 자전거 수요 예측**

- 자전거 수요 데이터같은 시계열 데이터로 생성한 RF같은 트리기반 모델은 효과적이지 못하다.
  - 테스트 데이터는 훈련 데이터 범위 밖. RF는 외삽할 수 없다.
  - 성능 향상을 위해선 전문가의 도움이 필요하다. 이 예제에서는 날짜와 시간을 따로 추출해 모델링에 사용했다.

<br>

**Ch 4 종합**

- 여러 가지 종류의 변수를 다루는 법을 배웠다.
  - One-hot-encoding 같이 ML 알고리즘에 맞게 데이터를 표현하는 것이 중요하다.
- <u>새로운 특성을 만드는 것, 전문가의 지식을 활용하는 법도 배웠다.</u>
- 선형 모델같은 경우 구간 분할, 상호작용, 다항식이 성능 향상에 큰 도움이 될 수 있다.
  - 반면 RF나 SVM같은 비선형 모델은 효과적이지 못하다. 어떤 특성을 사용하는지가 더 중요하다.

<br>

**Ch 5 모델 평가와 성능 향상**

- <u>비지도학습 모델 성능 평가는 매우 정성적이므로 생략.</u>

- 기존에는 `train_test_split()` 으로 훈련/테스트 데이터로 나누고, `score()` 메서드로 성능을 평가했다.
  - <u>`score()` 메서드는 정확히 분류된 비율을 계산한다. 회귀에는 $R^2$ 점수.</u>

- <u>데이터를 분할하는 이유는 훈련 데이터를 제외한 새 데이터에 얼마나 일반화되었는가 측정하기 위해서.</u>

<br>

**교차검증**

- 데이터를 k개로 나뉘어 한 개는 테스트 데이터, 나머지는 훈련 데이터로 사용해 총 k개의 모델로 학습한다.

<br>

**교차검증의 장단점**

- `train_test_split()` 은 무작위로 나뉘어 모델 성능이 훈련/테스트 데이터에 영향을 받는다. 하지만 교차 검증을 하면 각 데이터가 모두 훈련/테스트 데이터가 되므로 확실하다.
- <u>모델이 훈련 데이터에 얼마나 민감한지 알 수 있다.</u> 각 모델의 성능들로 최선, 최악의 예측 결과를 파악할 수 있다.
- 데이터셋을 보다 효과적으로 사용할 수 있다.
- k겹 교차검증은 k개의 모델을 생성하다보니 시간이 매우 오래걸리고 계산 비용도 높아진다.

<br>

**계층적 교차 검증**

- 데이터가 순서대로 되어있다면 기본 교차 검증은 효과적이지 못하다.
- 위의 단점을 해결하기 위해서 Stratified k-fold cross-validation을 사용한다. 데이터 클래스의 분포에 따라 각 폴드에 데이터가 분포된다.

<Br>

**교차 검증의 옵션**

- 보통 분류는 StratifiedKFold를, 회귀에는 기본 KFold를 사용한다.
- cv에 정수를 넣으면 분류일 경우 자동으로 StratifiedKFold.
- (1) cv=KFold
  - 기본 교차 검증 나누기.
- (2) cv=loo
  - LOOCV.  폴드 하나에 샘플 하나만 들어 있는 k-겹 교차 검증.
  - 큰 데이터셋에서는 계산이 매우 오래걸리지만, 작은 데이터셋에서는 가끔 성능을 내기도 한다.
- (3) cv=shufflesplit
  - 임의 분할 교차 검증. 데이터셋을 k개로 나누고 훈련/테스트 데이터를 정의한 개수만큼 사용하고 모델을 n번 반복한다.
  - 매개변수들을 따로 정의할 필요가 있을 때 효과적이다.
  - <u>전체 데이터에 일부만 사용할 수 있음.</u>
  - 이런 subsampling은 대규모 데이터셋에서 사용하면 좋다. 
  - 계층 버전은 StratifiedShuffleSplit.

