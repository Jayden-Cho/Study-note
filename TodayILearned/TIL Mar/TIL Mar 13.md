# Machine Learning

**ROC와 AUC**

- <u>DTS에 담긴 클래스가 아무리 불균형하더라도 무작위로 예측한 AUC 값은 0.5이다.</u>
- <u>AUC는 양성 샘플 순위를 평가하는 것으로 볼 수 있다.</u>
  - <u>임계치를 기준으로 기준 이상이면 양성.</u>

- <u>불균형한 DTS이 모델을 평가할 때는 AUC를 사용한다.</u>

<br>

**다중 분류에 대한 평가 지표**

- 이중 분류로부터 유도됐다. 각 클래스의 개수를 전체 샘플 개수로 나눈 것.
  - 이중 분류보다 이해하기 어려움.
- 다중 분류 평가는 정확도 외에 이진 분류에서 사용한 오차 행렬과 분류 리포트 사용.
  - 다중 분류의 오차 행렬에서:
    - <u>행은 양성인데 음성으로 분류한 것. 거짓 음성(FN).</u>
    - <u>열은 음성인데 양성으로 분류한 것. 거짓 양성(FP).</u>
- 다중 분류에서 불균형 데이터셋을 위해 가장 널리 사용하는 평가 지표는 $f_1$-점수.
  - 한 클래스를 제외한 나머지를 음성 클래스로 간주해 $f_1$-점수를 계산 후 평균을 내는데, 방법은 크게 세 가지가 있다.
    - `macro`: 그냥 모든 클래스를 동등하게.
    - `weighted`: 클래스 개수마다 가중치를 둬서.
    - `micro`: FN, TP, FP 사용해서. 

<Br>

**회귀에 대한 평가 지표**

- 회귀에도 많은 지표가 있지만, 대부분 $R^2$ 를 사용해도 충분하다.

<br>

**모델 선택할 때 사용하는 평가 지표**

- 성능 평가 이외에도 모델 선택 부분에도 평가 지표를 사용할 수 있다.
-  `GridSearchCV`, `cross_val_score`에 `scoring` 매개변수를 사용.
  - 분류: `accuracy`, `roc_auc`, `average_precision`, `f1`, `f1_macro`, `f1_weighted`, `f1_micro`
  - 회귀: `r2`, `mean_squared_error`, `mean_absolute_error`