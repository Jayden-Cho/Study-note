# Machine Learning

| 실제 음     | TN          | FP          |
| ----------- | ----------- | ----------- |
| **실제 양** | **FN**      | **TP**      |
|             | **예측 음** | **예측 양** |

**정확도**

- 전체 샘플 중 맞게 예측한 수. $$\frac{TN+TP}{TN+FP+FN+TP}$$

<br>

**정밀도, 재현율, f-점수**

- 정밀도: 전체 양성으로 예측한 샘플 중 실제 양성인 샘플의 수. $\frac{TP}{TP+FP}$
  - 거짓 양성을 줄이기 위해 사용됨.

- 재현율: 실제 양성 샘플 중에 양성으로 예측한 샘플의 수. $\frac{TP}{FN+TP}$
  - <u>모든 양성</u>을 파악하기 위해 사용됨.

- 정밀도와 재현율은 상충하는 개념.

- 정밀도, 재현율 모두 중요한 측정 방법이지만, 전체 그림을 파악하기는 어려움. 
- 그래서 f-점수를 사용. <u>정밀도/재현율을 하나로 요약해준다.</u>   $2\cdot\frac{정밀도\cdot재현율}{정밀도+재현율}$
  - 두 수치를 모두 사용해 파악할 수 있지만, 이해하기 어렵다.

- `classification_report`를 사용하면 정밀도, 재현율, f-점수 모두 출력한다.

<br>

**불확실성 고려**

- 오차 행렬, 분류 리포트 모두 예측 분석을 돕지만, <u>예측값은 이미 많은 정보가 손실된 상태</u>.
- 대부분의 분류기는 `decision_function`, `predict_proba`를 제공한다. 두 메서드로 예측의 정확도를 측정하자.
  - 두 메서드는 임계치를 설정하고 그 임계치를 넘으면 예측값이 된다.
- 정밀도/재현율을 조정하거나, 불균형 데이터셋에서는 임계치를 조정해보자.

<br>

**정밀도-재현율 곡선과 ROC 곡선**

- <u>모델의 분류 작업을 결정하는 임계값을 바꾸는 것은 재현율과 정밀도를 조정하는 것.</u>
- 목표를 설정하면 정밀도/재현율을 조정하기 쉬움. 그 목표를 운영 포인트라고 한다.
- <u>새 모델을 만들 때 운영 포인트가 명확하지 않은 경우가 있다. </u>
  - <u>모든 임계값을 조사하거나 한번에 정밀도/재현율을 살펴봐야 한다. 정밀도-재현율 곡선을 사용하자.</u>

- 정밀도-재현율 곡선은 오른쪽 위로 갈수록 성능이 좋다.

- 임계치가 높다.
  - 양성이 음성이 되는 경우가 있다 --> 재현율이 낮아진다
  - 음성을 양성으로 예측하는 경우가 적어진다 --> 정밀도가 높아진다
- 임계치가 낮다
  - 죄다 양성으로 분류한다 --> 재현율이 높아진다
  - 양성을 음성이라 예측하는 경우가 적어진다 --> 정밀도가 낮아진다
- 정밀도-재현율 곡선은 (1) 타깃 레이블, (2) `decision_function`, (3) `predict_proba`의 예측 불확실성을 사용한다.
- f-1 점수는 임계치가 기본값인 경우 단편적인 한 부분, 세부적인 부분을 놓칠수 있다. 
- 두 분류기의 정밀도-재현율 곡선을 일일히 분석하는 것은 너무 수작업. <u>전체 곡선에 대한 정보를 요약하는</u> 평균 정밀도를 사용.

<br>

**AUC 곡선**

- ROC 곡선과 비슷. 다만 재현율과 거짓 양성 비율을 plot.
  - 거짓 양성 비율은 전체 음성 샘플 중 거짓 양성으로 분류한 샘플의 수.
- 왼쪽 위에 가까울수록 좋은 성능.